<title>When and what to automate in software testing? A multi-vocal literature review</title>

<context>
Many organizations see software test automation as a solution to decrease testing costs and to reduce cycle time in software development. However, establishment of automated testing may fail if test automation is not applied in the right time, right context and with the appropriate approach.</context>
Objective
The decisions on when and what to automate is important since wrong decisions can lead to disappointments and major wrong expenditures (resources and efforts). To support decision making on when and what to automate, researchers and practitioners have proposed various guidelines, heuristics and factors since the early days of test automation technologies. As the number of such sources has increased, it is important to systematically categorize the current state-of-the-art and -practice, and to provide a synthesized overview.
Method
To achieve the above objective, we have performed a Multivocal Literature Review (MLR) study on when and what to automate in software testing. A MLR is a form of a Systematic Literature Review (SLR) which includes the grey literature (e.g., blog posts and white papers) in addition to the published (formal) literature (e.g., journal and conference papers). We searched the academic literature using the Google Scholar and the grey literature using the regular Google search engine.

<results>
	<result>
		Our MLR and its results are based on 78 sources, 52 of which were grey literature and 26 were formally published sources.
		<TypeOfResult>Quantitative</TypeOfResult> 
	</result>
	<result>
		We used the qualitative analysis (coding) to classify the factors affecting the when and what-to-automate questions to five groups: (a) Software Under Test (SUT)-related factors, (b) test-related factors, (c) test-tool-related factors, (d) human and organizational factors, and (e) cross-cutting and other factors. 
		<TypeOfResult>Qualitative</TypeOfResult>
	</result>
	<result>
		The most frequent individual factors were: need for regression testing (44 sources), economic factors (43), and maturity of SUT (39).
		<TypeOfResult>Quantitative</TypeOfResult>
	</result>
</results>

Conclusion
We show that current decision-support in software test automation provides reasonable advice for industry, and as a practical outcome of this research we have summarized it as a checklist that can be used by practitioners. However, we recommend developing systematic empirically-validated decision-support approaches as the existing advice is often unsystematic and based on weak empirical evidence.
